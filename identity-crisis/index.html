<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MediaPipe Face Detection Demo</title>
    <style>
        @font-face {
            font-family: 'Mondwest';
            src: url('Mondwest-Regular.otf') format('opentype');
            font-weight: normal;
            font-style: normal;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            background: #000;
            overflow: hidden;
            font-family: Arial, sans-serif;
        }

        #container {
            position: relative;
            width: 100vw;
            height: 100vh;
        }

        #video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1); /* Mirror the video */
        }

        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
            transform: scaleX(-1); /* Mirror the canvas to match video */
        }

        #status {
            position: absolute;
            top: 20px;
            left: 20px;
            color: white;
            background: rgba(0, 0, 0, 0.7);
            padding: 10px 15px;
            border-radius: 5px;
            font-size: 14px;
            z-index: 10;
        }

        #error {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: #ff4444;
            background: rgba(0, 0, 0, 0.8);
            padding: 20px;
            border-radius: 10px;
            text-align: center;
            display: none;
        }
    </style>
</head>
<body>
    <div id="container">
        <video id="video" autoplay playsinline></video>
        <canvas id="canvas"></canvas>
        <div id="status">Loading MediaPipe...</div>
        <div id="error">
            <h3>Error</h3>
            <p id="error-message"></p>
        </div>
    </div>

    <script type="module">
        import { FaceDetector, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const status = document.getElementById('status');
        const errorDiv = document.getElementById('error');
        const errorMessage = document.getElementById('error-message');

        let faceDetector;
        let runningMode = "VIDEO";
        let lastVideoTime = -1;
        let globalConfidence = 0; // Track overall confidence
        let messageRotationIndex = 0; // Global rotation index
        let confidenceChangeThreshold = 2; // Only rotate when confidence changes by this amount

        // Array of existential crisis messages
        const existentialMessages = [
            "I don't know who I am",
            "I don't know what I'm doing with my life", 
            "What do I do with my life",
            "Am I even real right now",
            "Is this my best angle tho",
            "Why am I like this",
            "I'm having an identity crisis",
            "Who even am I anymore",
            "I'm just vibing honestly",
            "This is my villain origin story"
        ];

        function showError(message) {
            errorMessage.textContent = message;
            errorDiv.style.display = 'block';
            status.style.display = 'none';
        }

        function updateStatus(message) {
            status.textContent = message;
        }

        function resizeCanvas() {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
        }

        function drawResults(results) {
            // Clear canvas
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            if (results.detections && results.detections.length > 0) {
                updateStatus(`Faces detected: ${results.detections.length}`);
                
                // Get the primary face (largest or first detected)
                const primaryDetection = results.detections[0];
                if (primaryDetection.categories && primaryDetection.categories.length > 0) {
                    const currentConfidence = Math.round(primaryDetection.categories[0].score * 100);
                    
                    // Check if confidence changed significantly
                    if (Math.abs(currentConfidence - globalConfidence) >= confidenceChangeThreshold) {
                        messageRotationIndex = (messageRotationIndex + 1) % existentialMessages.length;
                        globalConfidence = currentConfidence;
                    }
                }
                
                results.detections.forEach((detection, index) => {
                    // Get bounding box - MediaPipe provides pixel coordinates
                    const bbox = detection.boundingBox;
                    
                    // Scale to canvas size
                    const canvasRatio = Math.min(canvas.width / video.videoWidth, canvas.height / video.videoHeight);
                    const offsetX = (canvas.width - video.videoWidth * canvasRatio) / 2;
                    const offsetY = (canvas.height - video.videoHeight * canvasRatio) / 2;
                    
                    const x = bbox.originX * canvasRatio + offsetX;
                    const y = bbox.originY * canvasRatio + offsetY;
                    const width = bbox.width * canvasRatio;
                    const height = bbox.height * canvasRatio;

                    // Draw camera frame/viewfinder
                    ctx.strokeStyle = '#ffb3d9';
                    ctx.lineWidth = 4;
                    
                    // Draw corner brackets instead of full rectangle
                    const cornerLength = Math.min(width, height) * 0.15; // 15% of the smaller dimension
                    
                    // Top-left corner
                    ctx.beginPath();
                    ctx.moveTo(x, y + cornerLength);
                    ctx.lineTo(x, y);
                    ctx.lineTo(x + cornerLength, y);
                    ctx.stroke();
                    
                    // Top-right corner
                    ctx.beginPath();
                    ctx.moveTo(x + width - cornerLength, y);
                    ctx.lineTo(x + width, y);
                    ctx.lineTo(x + width, y + cornerLength);
                    ctx.stroke();
                    
                    // Bottom-left corner
                    ctx.beginPath();
                    ctx.moveTo(x, y + height - cornerLength);
                    ctx.lineTo(x, y + height);
                    ctx.lineTo(x + cornerLength, y + height);
                    ctx.stroke();
                    
                    // Bottom-right corner
                    ctx.beginPath();
                    ctx.moveTo(x + width - cornerLength, y + height);
                    ctx.lineTo(x + width, y + height);
                    ctx.lineTo(x + width, y + height - cornerLength);
                    ctx.stroke();
                    
                    // Draw center crosshair/focus point
                    const centerX_frame = x + width / 2;
                    const centerY_frame = y + height / 2;
                    const crosshairSize = 10;
                    
                    ctx.beginPath();
                    ctx.moveTo(centerX_frame - crosshairSize, centerY_frame);
                    ctx.lineTo(centerX_frame + crosshairSize, centerY_frame);
                    ctx.moveTo(centerX_frame, centerY_frame - crosshairSize);
                    ctx.lineTo(centerX_frame, centerY_frame + crosshairSize);
                    ctx.stroke();
                    
                    // Add small circle in center
                    ctx.beginPath();
                    ctx.arc(centerX_frame, centerY_frame, 3, 0, 2 * Math.PI);
                    ctx.stroke();

                    // Draw confidence percentage
                    if (detection.categories && detection.categories.length > 0) {
                        const confidence = Math.round(detection.categories[0].score * 100);
                        
                        // Get current message (same for all faces)
                        const currentMessage = existentialMessages[messageRotationIndex];
                        
                        ctx.fillStyle = '#ffb3d9';
                        ctx.font = '36px Mondwest, Arial';
                        ctx.strokeStyle = '#ff0000';
                        ctx.lineWidth = 4;
                        ctx.textAlign = 'center';
                        ctx.textBaseline = 'middle';
                        
                        const text = `${currentMessage}\n${confidence}%`;
                        
                        // Calculate top position of the bounding box
                        const centerX = x + width / 2;
                        const topY = y + 30; // Position near the top of the box
                        
                        // Save the current transformation
                        ctx.save();
                        
                        // Flip the text horizontally to reverse it
                        ctx.scale(-1, 1);
                        
                        // Draw text with outline at center (adjust x position for flip)
                        // Split text into lines and draw each line separately
                        const lines = text.split('\n');
                        const lineHeight = 40;
                        const totalHeight = lines.length * lineHeight;
                        const startY = topY;
                        
                        lines.forEach((line, index) => {
                            const lineY = startY + index * lineHeight;
                            ctx.strokeText(line, -centerX, lineY);
                            ctx.fillText(line, -centerX, lineY);
                        });
                        
                        // Restore the transformation and text alignment
                        ctx.restore();
                        ctx.textAlign = 'start';
                        ctx.textBaseline = 'alphabetic';
                    }
                });
            } else {
                updateStatus('No faces detected');
            }
        }

        async function initMediaPipe() {
            try {
                updateStatus('Loading MediaPipe model...');
                
                // Initialize the FilesetResolver
                const vision = await FilesetResolver.forVisionTasks(
                    "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
                );

                // Create FaceDetector
                faceDetector = await FaceDetector.createFromOptions(vision, {
                    baseOptions: {
                        modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite',
                        delegate: "GPU"
                    },
                    runningMode: runningMode,
                    minDetectionConfidence: 0.5
                });
                
                updateStatus('MediaPipe model loaded. Starting camera...');
                await initCamera();
                
            } catch (error) {
                console.error('MediaPipe initialization error:', error);
                showError('Failed to initialize MediaPipe: ' + error.message);
            }
        }

        async function initCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: { ideal: 1280 },
                        height: { ideal: 720 },
                        facingMode: 'user'
                    }
                });

                video.srcObject = stream;
                
                video.onloadedmetadata = () => {
                    video.play();
                    updateStatus('Camera ready. Detecting faces...');
                    startDetection();
                };

            } catch (error) {
                console.error('Camera access error:', error);
                showError('Failed to access camera. Please ensure camera permissions are granted.');
            }
        }
        
        function startDetection() {
            const detect = async () => {
                if (video.readyState === 4 && video.videoWidth > 0) {
                    const currentTime = video.currentTime;
                    
                    // Only process if we have a new frame
                    if (currentTime !== lastVideoTime) {
                        lastVideoTime = currentTime;
                        
                        try {
                            // Detect faces in the current video frame
                            const results = faceDetector.detectForVideo(video, performance.now());
                            drawResults(results);
                        } catch (error) {
                            console.error('Detection error:', error);
                        }
                    }
                }
                requestAnimationFrame(detect);
            };
            detect();
        }

        // Handle window resize
        window.addEventListener('resize', resizeCanvas);
        
        // Initialize everything
        window.addEventListener('load', () => {
            resizeCanvas();
            initMediaPipe();
        });

        // Handle page visibility change
        document.addEventListener('visibilitychange', () => {
            if (document.hidden) {
                updateStatus('Paused (tab not visible)');
            } else if (faceDetector) {
                updateStatus('Detecting faces...');
            }
        });
    </script>
</body>
</html>